{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fast_ai_text_multi_label.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jameszlj/NLP_with_python/blob/master/fast_ai_text_multi_label.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xvOlOkARF7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.text import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpxpVdPfSH18",
        "colab_type": "code",
        "outputId": "c35f835c-3115-4dab-bd6c-22417c93ec2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "!pip install pytorch-transformers"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-transformers in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (4.28.1)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.2.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (0.1.83)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.9.243)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.16.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2019.8.19)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2.21.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (0.0.35)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.243 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (1.12.243)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.2.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2019.9.11)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (0.14.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (1.12.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.243->boto3->pytorch-transformers) (2.5.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.243->boto3->pytorch-transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5S-bAXFSyYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pytorch_transformers import BertTokenizer, BertForSequenceClassification\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "class BertFastaiTokenizer(BaseTokenizer):\n",
        "    def __init__(self, tokenizer, max_seq_len=128, **kwargs):\n",
        "        self.pretrained_tokenizer = tokenizer\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self\n",
        "\n",
        "    def tokenizer(self, t):\n",
        "        return [\"[CLS]\"] + self.pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2] + [\"[SEP]\"]\n",
        "\n",
        "\n",
        "class MyNoTupleModel(BertForSequenceClassification):\n",
        "    def forward(self, *args, **kwargs):\n",
        "        return super().forward(*args, **kwargs)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Be0t1X6TJSr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_seq_len = 256\n",
        "batch_size = 32\n",
        "path = Path(\".\")\n",
        "bert_model = \"bert-base-uncased\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rtq4TUYnTTh5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test = [pd.read_csv(path / fname) for fname in [\"train.csv\", \"test.csv\"]]\n",
        "train, valid = train_test_split(train, random_state=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_851PaeXD_P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "outputId": "85704a34-fb2b-44f6-b433-05c26b82ee15"
      },
      "source": [
        "train.head(10)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5400</th>\n",
              "      <td>0e65327b5bbee0a5</td>\n",
              "      <td>\"\\n\\nI think it is both a Khmer character and ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122278</th>\n",
              "      <td>8e162cbf88bfc540</td>\n",
              "      <td>\"\\nI have added information to the article cre...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115832</th>\n",
              "      <td>6b646f8e87da9b5f</td>\n",
              "      <td>Thanks kmccoy, I could really use your help on...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125459</th>\n",
              "      <td>9f1ab871e0d50caf</td>\n",
              "      <td>\"\\nI never heard that, and I can't find any re...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131403</th>\n",
              "      <td>befbff9b502b865f</td>\n",
              "      <td>\"\\n\\nWell objectively, 200 PKK militants train...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158699</th>\n",
              "      <td>f218b5761c26faaa</td>\n",
              "      <td>I was thinking just adding a bullet point to t...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75648</th>\n",
              "      <td>ca678d42144fbb2d</td>\n",
              "      <td>Your objections to that sentence are quite cor...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118733</th>\n",
              "      <td>7a8f77565e0df03e</td>\n",
              "      <td>Thanks for being late to the party \\n\\nbut I h...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115153</th>\n",
              "      <td>67b7eec36480cd1c</td>\n",
              "      <td>I give up trying to write a page today. You lo...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109009</th>\n",
              "      <td>46dd6c0f2cdca00c</td>\n",
              "      <td>\"\\n\\n Robots everywhere! \\n\\nI see you have me...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      id  ... identity_hate\n",
              "5400    0e65327b5bbee0a5  ...             0\n",
              "122278  8e162cbf88bfc540  ...             0\n",
              "115832  6b646f8e87da9b5f  ...             0\n",
              "125459  9f1ab871e0d50caf  ...             0\n",
              "131403  befbff9b502b865f  ...             0\n",
              "158699  f218b5761c26faaa  ...             0\n",
              "75648   ca678d42144fbb2d  ...             0\n",
              "118733  7a8f77565e0df03e  ...             0\n",
              "115153  67b7eec36480cd1c  ...             0\n",
              "109009  46dd6c0f2cdca00c  ...             0\n",
              "\n",
              "[10 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_H00mhHXTgig",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "db27613a-d157-48f9-e006-cf9b0f05cf73"
      },
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained(bert_model)\n",
        "print(list(bert_tokenizer.vocab.items())[1000:1005])\n",
        "bert_vocab = Vocab(list(bert_tokenizer.vocab.keys()))\n",
        "tok_func = BertFastaiTokenizer(bert_tokenizer, max_seq_len=max_seq_len)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 1227939.08B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[('\"', 1000), ('#', 1001), ('$', 1002), ('%', 1003), ('&', 1004)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz2aqpSIVNyV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "07366a0d-362a-4746-a435-6fdb847facd2"
      },
      "source": [
        "bert_fastai_tokenizer = Tokenizer(tok_func=tok_func, pre_rules=[], post_rules=[])\n",
        "label_cols = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "## preprocess databunch\n",
        "databunch = TextClasDataBunch.from_df(path, train, valid, test,\n",
        "                                      tokenizer=bert_fastai_tokenizer,\n",
        "                                      vocab=bert_vocab,\n",
        "                                      include_bos=False,\n",
        "                                      include_eos=False,\n",
        "                                      text_cols=\"comment_text\",\n",
        "                                      label_cols=label_cols,\n",
        "                                      bs=batch_size,\n",
        "                                      collate_fn=partial(pad_collate, pad_first=False, pad_idx=0),\n",
        "                                      )\n",
        "databunch.show_batch()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>[CLS] english english vs american english vs . . . in an earlier edit changing petrol to gas , i wrote in the edit comment that i was changing the word ##ing to american english ( gas ) because that ' s the standard for this wikipedia . another user pointed out that my assertion of an american english standard for this wikipedia was incorrect according to the wikipedia manual</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[CLS] you ' re fucking gay . get a job and quit arguing with people on the internet . it doesn ' t make you cool , you aren ' t adding shit , you ' re just making it worse . get a fucking life . you ' re fucking gay . get a job and quit arguing with people on the internet . it doesn ' t make</td>\n",
              "      <td>toxic;obscene;insult;identity_hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[CLS] \" thanks for the help hey , thanks for directing me to the breeding ##bet ##tas page , even though it didn ' t have the exact info i was looking for , it did help with some other questions i had . porsche ##9 ##9 ##7 ##sb ##s . . . big thanks for the automobiles user ##box ##es . hope a mustang ( usa ) will turn</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[CLS] hello fran ##ia . i never mentioned anything yet about charles vii . it had no con ##tri ##dict ##ing in fact ##n with sal ##ic law as it was only su ##cc ##est ##ion for the private norm and in fact had nothing to do with france . it was used as a cover up rather then a legal law in a council held in 131 ##7 .</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[CLS] london boroughs thanks for reviewing some of the london boroughs pages , as you ' ve noticed most are in a distress ##ing state - and it ' s a good day when the page is extended from harmless to mostly harmless . i would however urge you to use the fact tag spa ##ring ##ly - either for things that don ' t make sense , or that</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LjuUZ9KWR69",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "28bba25f-35de-4049-9f79-9191eae1cfd7"
      },
      "source": [
        "bert_pretrained_model = MyNoTupleModel.from_pretrained(bert_model, num_labels=6)\n",
        "loss_func = nn.BCEWithLogitsLoss()\n",
        "learn = Learner(databunch,\n",
        "                bert_pretrained_model,\n",
        "                loss_func=loss_func,\n",
        "                metrics=accuracy)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:00<00:00, 74791.61B/s]\n",
            "100%|██████████| 440473133/440473133 [00:11<00:00, 36750213.67B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgEIPjNtWmdn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "7e6a02d8-c23b-48c1-81be-ebee89a23872"
      },
      "source": [
        "learn.lr_find()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d81c6bd29d71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'learn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFSbZJUWWqGz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.recorder.plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISyR1-56WuFL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.fit_one_cycle(4, 3e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}