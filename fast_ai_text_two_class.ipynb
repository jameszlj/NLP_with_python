{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fast_ai_text_two_class.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jameszlj/NLP_with_python/blob/master/fast_ai_text_two_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-HkYxo2GZT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.text import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDiShwEi27Jh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUU3lFXrXAUw",
        "colab_type": "code",
        "outputId": "d2cd7420-dccb-490e-fd15-bde95cd43d6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "!wget https://github.com/wshuyi/public_datasets/raw/master/dianping.csv"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-12 09:00:06--  https://github.com/wshuyi/public_datasets/raw/master/dianping.csv\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/wshuyi/public_datasets/master/dianping.csv [following]\n",
            "--2019-10-12 09:00:06--  https://raw.githubusercontent.com/wshuyi/public_datasets/master/dianping.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 531037 (519K) [text/plain]\n",
            "Saving to: ‘dianping.csv’\n",
            "\n",
            "\rdianping.csv          0%[                    ]       0  --.-KB/s               \rdianping.csv        100%[===================>] 518.59K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2019-10-12 09:00:07 (17.9 MB/s) - ‘dianping.csv’ saved [531037/531037]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGoDtc0Z3CFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDfYplnJM0A-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"dianping.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbjT_fQb3FnN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8m0iT14NAJz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUWWbsurNHRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test = train_test_split(df, test_size=.2, random_state=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTlBj0_vNOGs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, valid = train_test_split(train, test_size=.2, random_state=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5M58ohRXNRma",
        "colab_type": "code",
        "outputId": "6b5d506f-c5c5-41be-c51f-61df8575d082",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1280"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwYryualNV1U",
        "colab_type": "code",
        "outputId": "97e1b17e-46fb-4d00-cc30-d94d9a319dd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(valid)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "320"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWWYv75WNW9l",
        "colab_type": "code",
        "outputId": "52dd3f86-6e50-4d17-e2d7-3fcff5f0f6b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ot3umGoNSw2",
        "colab_type": "code",
        "outputId": "2917f114-69d3-4757-ff76-ea85b4f808d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>330</th>\n",
              "      <td>跟老公去大悦城玩儿的时候吃的，味道真的还不错哦！这家店是一对年轻的小两口自主创业开的店，环境...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1326</th>\n",
              "      <td>味道是好，但是真的很生气，排了两个小时的队伍就为了吃干酪鱼，进来被告知没有了，我觉得起码没有...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>666</th>\n",
              "      <td>还好吧，调调不错，排队人多。。</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1753</th>\n",
              "      <td>星期一人依旧是那么多，五点刚过就到了，基本上坐满了。菜品种类不少，这次赶上了青口贝挺好的。烤...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1885</th>\n",
              "      <td>4点半进去没等座。大拉皮好实惠。麻酱别都放否则太甜。薰骨肉香味浓。家常茄子精工细做，很好。还...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                comment  sentiment\n",
              "330   跟老公去大悦城玩儿的时候吃的，味道真的还不错哦！这家店是一对年轻的小两口自主创业开的店，环境...          1\n",
              "1326  味道是好，但是真的很生气，排了两个小时的队伍就为了吃干酪鱼，进来被告知没有了，我觉得起码没有...          0\n",
              "666                                     还好吧，调调不错，排队人多。。          1\n",
              "1753  星期一人依旧是那么多，五点刚过就到了，基本上坐满了。菜品种类不少，这次赶上了青口贝挺好的。烤...          1\n",
              "1885  4点半进去没等座。大拉皮好实惠。麻酱别都放否则太甜。薰骨肉香味浓。家常茄子精工细做，很好。还...          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZfxHR-N3Oe4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3gQIfrZJ8h7",
        "colab_type": "code",
        "outputId": "40c2bfa5-7a0f-4372-ba18-ff134e7663d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        }
      },
      "source": [
        "!pip install pytorch-transformers"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
            "\r\u001b[K     |█▉                              | 10kB 17.5MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 40kB 3.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 51kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 61kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 81kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 92kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 102kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 112kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 122kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 133kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 143kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 153kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 163kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 174kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2.21.0)\n",
            "Collecting sacremoses (from pytorch-transformers)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
            "\r\u001b[K     |▍                               | 10kB 19.8MB/s eta 0:00:01\r\u001b[K     |▊                               | 20kB 25.9MB/s eta 0:00:01\r\u001b[K     |█▏                              | 30kB 31.9MB/s eta 0:00:01\r\u001b[K     |█▌                              | 40kB 35.6MB/s eta 0:00:01\r\u001b[K     |██                              | 51kB 36.7MB/s eta 0:00:01\r\u001b[K     |██▎                             | 61kB 37.6MB/s eta 0:00:01\r\u001b[K     |██▊                             | 71kB 38.4MB/s eta 0:00:01\r\u001b[K     |███                             | 81kB 39.6MB/s eta 0:00:01\r\u001b[K     |███▍                            | 92kB 41.3MB/s eta 0:00:01\r\u001b[K     |███▉                            | 102kB 41.7MB/s eta 0:00:01\r\u001b[K     |████▏                           | 112kB 41.7MB/s eta 0:00:01\r\u001b[K     |████▋                           | 122kB 41.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 133kB 41.7MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 143kB 41.7MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 153kB 41.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 163kB 41.7MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 174kB 41.7MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 184kB 41.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 194kB 41.7MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 204kB 41.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 215kB 41.7MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 225kB 41.7MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 235kB 41.7MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 245kB 41.7MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 256kB 41.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 266kB 41.7MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 276kB 41.7MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 286kB 41.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 296kB 41.7MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 307kB 41.7MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 317kB 41.7MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 327kB 41.7MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 337kB 41.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 348kB 41.7MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 358kB 41.7MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 368kB 41.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 378kB 41.7MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 389kB 41.7MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 399kB 41.7MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 409kB 41.7MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 419kB 41.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 430kB 41.7MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 440kB 41.7MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 450kB 41.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 460kB 41.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 471kB 41.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 481kB 41.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 491kB 41.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 501kB 41.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 512kB 41.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 522kB 41.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 532kB 41.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 542kB 41.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 552kB 41.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 563kB 41.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 573kB 41.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 583kB 41.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 593kB 41.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 604kB 41.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 614kB 41.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 624kB 41.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 634kB 41.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 645kB 41.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 655kB 41.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 665kB 41.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 675kB 41.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 686kB 41.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 696kB 41.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 706kB 41.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 716kB 41.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 727kB 41.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 737kB 41.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 747kB 41.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 757kB 41.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 768kB 41.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 778kB 41.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 788kB 41.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 798kB 41.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 808kB 41.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 819kB 41.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 829kB 41.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 839kB 41.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 849kB 41.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 860kB 41.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.9.243)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.2.0)\n",
            "Collecting regex (from pytorch-transformers)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/a6/99eeb5904ab763db87af4bd71d9b1dfdd9792681240657a4c0a599c10a81/regex-2019.08.19.tar.gz (654kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 37.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.16.5)\n",
            "Collecting sentencepiece (from pytorch-transformers)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 31.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (4.28.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2019.9.11)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (0.14.0)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.243 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (1.12.243)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.9.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.243->boto3->pytorch-transformers) (2.5.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.243->boto3->pytorch-transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses, regex\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=81801ec66268c04d46c4240577be546b55a511cadd87a349e4bb15f823303931\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2019.8.19-cp36-cp36m-linux_x86_64.whl size=609235 sha256=19961e21c40f20aa04ae082c7a9e3db7d6fc5a023b594f9790ee9efffa019d44\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/04/07/b5010fb816721eb3d6dd64ed5cc8111ca23f97fdab8619b5be\n",
            "Successfully built sacremoses regex\n",
            "Installing collected packages: sacremoses, regex, sentencepiece, pytorch-transformers\n",
            "Successfully installed pytorch-transformers-1.2.0 regex-2019.8.19 sacremoses-0.0.35 sentencepiece-0.1.83\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGPWStCvKASr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pytorch_transformers import BertTokenizer, BertForSequenceClassification"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dS1_jNESiEv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_model = \"bert-base-chinese\"\n",
        "max_seq_len = 128\n",
        "batch_size = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiKPDWViStZS",
        "colab_type": "code",
        "outputId": "9bb0dfc5-2d98-4300-a722-41254a9931bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained(bert_model)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 109540/109540 [00:00<00:00, 650490.53B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxXk9yB1V0nB",
        "colab_type": "code",
        "outputId": "87f10689-9811-416d-ed60-2381da15a1cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "list(bert_tokenizer.vocab.items())[2000:2005]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('姗', 2000), ('姚', 2001), ('姜', 2002), ('姝', 2003), ('姣', 2004)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYIrjtkHW2F2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_vocab = Vocab(list(bert_tokenizer.vocab.keys()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHXvwk8VGyq1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertFastaiTokenizer(BaseTokenizer):\n",
        "    def __init__(self, tokenizer, max_seq_len=128, **kwargs):\n",
        "        self.pretrained_tokenizer = tokenizer\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self\n",
        "\n",
        "    def tokenizer(self, t):\n",
        "        return [\"[CLS]\"] + self.pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2] + [\"[SEP]\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BW8yrL48W7iX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tok_func = BertFastaiTokenizer(bert_tokenizer, max_seq_len=max_seq_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HD1qCGCVMMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_fastai_tokenizer = Tokenizer(\n",
        "    tok_func=tok_func,\n",
        "    pre_rules = [],\n",
        "    post_rules = []\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTOtOYvvNfVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = Path(\".\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FmN5wWFNbcj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "databunch = TextClasDataBunch.from_df(path, train, valid, test,\n",
        "                  tokenizer=bert_fastai_tokenizer,\n",
        "                  vocab=bert_vocab,\n",
        "                  include_bos=False,\n",
        "                  include_eos=False,\n",
        "                  text_cols=\"comment\",\n",
        "                  label_cols='sentiment',\n",
        "                  bs=batch_size,\n",
        "                  collate_fn=partial(pad_collate, pad_first=False, pad_idx=0),\n",
        "             )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAH_8yNQOEI7",
        "colab_type": "code",
        "outputId": "2ac7c96a-d38a-43e8-bd5b-0eda0d0e7666",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "databunch.show_batch()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>[CLS] 第 一 次 去 吃 是 国 庆 期 间 ， 吃 五 十 返 五 十 ！ 说 实 话 确 实 有 些 菜 不 错 ！ 拿 着 返 券 第 二 次 再 去 的 时 候 ！ 略 有 失 望 ！ 妈 妈 熏 排 骨 第 二 次 点 的 大 份 ， 比 第 一 次 第 一 次 点 的</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[CLS] 早 就 听 说 过 他 家 不 错 ， 但 是 由 于 听 闻 一 直 太 火 爆 ， 导 致 一 直 没 有 去 拔 草 。 上 星 期 终 于 吃 到 啦 ， 工 作 日 的 中 午 去 的 ， 11 点 多 那 时 候 已 经 人 头 攒 动 了 。 先 说 配 餐 ，</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[CLS] 实 在 不 理 解 为 什 么 点 评 这 么 火 ， 外 边 还 有 好 多 人 排 队 。 这 个 菜 的 口 味 放 北 京 也 许 是 正 常 的 ， 但 是 在 天 津 这 种 风 味 水 平 根 本 不 值 得 尝 试 ， 更 别 提 排 队 了 。 随 便 找</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[CLS] 如 果 能 打 负 分 的 话 一 定 给 他 打 负 分 ， 可 惜 没 有 ！ 跟 朋 友 聚 会 去 的 这 家 自 助 、 大 周 五 的 差 不 多 8 点 应 该 也 不 是 很 晚 吧 ， 几 个 人 进 去 后 东 西 都 没 有 什 么 了 ， 服 务 员</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[CLS] 先 团 的 券 ， 进 去 后 就 不 想 吃 了 ， 把 券 退 了 ， 因 为 同 伴 拿 了 一 杯 水 回 来 ， 服 务 员 告 知 必 须 交 钱 了 ， 那 就 在 这 吃 吧 。 结 果 交 的 现 金 。 客 观 的 说 ， 东 西 种 类 是 不 少 ，</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5wzcUQ1YJ7y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyNoTupleModel(BertForSequenceClassification):\n",
        "  def forward(self, *args, **kwargs):\n",
        "    return super().forward(*args, **kwargs)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bWsk4psVJd2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "4a65871e-6bd4-4423-b6dc-848600fe9622"
      },
      "source": [
        "bert_pretrained_model = MyNoTupleModel.from_pretrained(bert_model, num_labels=2)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 520/520 [00:00<00:00, 144871.34B/s]\n",
            "100%|██████████| 411577189/411577189 [00:13<00:00, 29549860.83B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBM9tcDdVb8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoZZjQ9pPbdt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(databunch, \n",
        "                bert_pretrained_model,\n",
        "                loss_func=loss_func,\n",
        "                metrics=accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FyFLUnBExxA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.set_device(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukNa5Ea8LjsM",
        "colab_type": "code",
        "outputId": "04810329-a5c4-4f41-8a57-e61cf900b057",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    print(bert_pretrained_model.cuda())\n",
        "    print(\"Check Done\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MyNoTupleModel(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
            ")\n",
            "Check Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HU-sNOHfTpTp",
        "colab_type": "code",
        "outputId": "fdf3ccdd-3664-40a0-c544-75f2e623b5d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "learn.lr_find()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPFIFxcnUB9P",
        "colab_type": "code",
        "outputId": "16035f30-e508-4df3-d752-7a08849f4e51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "learn.recorder.plot()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDJDRZRsRGFI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "5b1b729e-c79a-42c3-c3be-46c2a6b92252"
      },
      "source": [
        "learn.fit_one_cycle(2, 2e-5)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.554093</td>\n",
              "      <td>0.363615</td>\n",
              "      <td>0.859375</td>\n",
              "      <td>00:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.379899</td>\n",
              "      <td>0.286867</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>00:36</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHNMEpOAH3yN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dumb_series_prediction(n):\n",
        "  preds = []\n",
        "  for loc in range(n):\n",
        "    preds.append(int(learn.predict(test.iloc[loc]['comment'])[1]))\n",
        "  return preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuhWUTdhn_UF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = dumb_series_prediction(len(test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvPRjZ_xoB80",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "24d04854-2db8-4a92-9e7b-7a8518f4793f"
      },
      "source": [
        "preds[:10]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1, 1, 1, 1, 0, 1, 1, 0, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9NCp8k5hcnd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcJbaF-7hezH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "40b6b80d-4286-46bd-cdc9-fbb66888b55e"
      },
      "source": [
        "print(classification_report(test.sentiment, preds))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.88      0.88       203\n",
            "           1       0.88      0.88      0.88       197\n",
            "\n",
            "    accuracy                           0.88       400\n",
            "   macro avg       0.88      0.88      0.88       400\n",
            "weighted avg       0.88      0.88      0.88       400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWZXJ3iw-Zdv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "98b6d747-9d8d-4695-b913-d3ac900b31fa"
      },
      "source": [
        "print(confusion_matrix(test.sentiment, preds))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[179  24]\n",
            " [ 23 174]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IKLzdgDp2j8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}